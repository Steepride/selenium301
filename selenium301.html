<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Sauce Laboratories - Selenium 301 </title>

		<meta name="description" content="Learn how to configure, test, and manage test in your Sauce Lab enterprise environment">
		<meta name="author" content="James Tacker">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/sauce.css" id="theme">

    <!--favicon-->
        <link rel="shortcut icon" href="assets/images/sauce_favicon.ico" type="image/x-icon" />

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

	  <div class="reveal">

        <style>
          .reveal .slides { text-align: left; }
          .reveal .slides h1 { text-align: center; }
          .reveal .slides h2 { text-align: center; }
          .reveal .slides h3 { text-align: center; font-variant: none; text-transform: none;}
        </style>
		<!-- Any section element inside of this container is displayed as a slide -->

        <img src="assets/images/saucelabslogo.png" style="border:0; width:100px; height:100px; background:none; position:absolute; left:0; top:0;">
        <img id="lab_pic" src="assets/images/Laboratory2.png" style="visibility:hidden; border:0; width:200px; height:200px; background:none; position:absolute; right:0; top:0;">

	        <div class="slides">

              <section data-background="rgb(226, 35, 26)">
                <h1>Selenium 301</h1>

                <p style="text-align:center">
	              <small><i>Testing at the speed of Awesome</i></small>
                </p>

                <p style="text-align:center">
                  <small>
                    <small>Using Reveal.js</small>
                  </small>
                </p>
              </section>

                       <section>
    <h3>Trainer Introduction</h3>
<!-- left column-->
                    <div style="float:left;width:50%;" class="centered">
                      
                      <p><strong>James Tacker</strong></p>
                      <p>Tech Consultant and Trainer</p>
                      <p>Previous Work:</p>
                      <ul>
                        <li>Atlassian</li>
                        <li>NGINX</li>
                        <li>New Relic</li>
                      </ul>
                      <p><a href="mailto:james.tacker@servicerocket.com">james.tacker@servicerocket.com</a></p>
            
                    </div>
<!-- right column-->
                    <div style="float:right;width:40%;padding-right:0px;">
                      <img src="assets/images/picture1.png" style="border:0;background:none; left:0; top:0;">
                    </div>
        </section>

              <section>
                <h3>Agenda</h3>

                <div style="text-align:left;">
                    <img src="assets/images/sauceAgenda.png" style="border:none; background:none; width:80%">
                  </div>
                
              </section>

<!-- Scaling Automated Tests-->
  <section data-background="rgb(226, 35, 26)">
    <h2>Scaling Automated Tests</h2>
      <aside class="notes"></aside>
      </section>

    <section>
      <h3>Module Objectives</h3>
        <p>This module enables you to:</p>
          <ul>
          <li>Optimize your parallelized test builds</li>
          <li>Abstract components into page objects in order to onboard team members quickly</li>
          </ul>
        <aside class="notes"></aside>
        </section>
                <section>
    <h3>Scaling Tips</h3>
    <ul>
        <li>Page Objects for Robust Testing</li>
        <li>Frameworks for Parallelization</li>
        <li>Jenkins for Automated Builds</li>
          </ul>
      <aside class="notes">
          <p>Running tests in parallel is the secret Sauce for accelerating your development process and creating a continuous integration/continuous delivery pipeline.</p>
          <p>One of the main features that Sauce Labs offers is parallelization, the ability to run serveral scripts at once on a variety of platforms. Since tests and commands are sent remotely, these tests take longer to run individually, but with parallelization, we can run them all at once. That is, we can start them all at the same time, which cuts down on the total time tests would normally take, saving time and money for your teams and business.</p>
          <p>It's good to avoid dependencies between tests. This goes along with the atomic testing strategy, where we want to create autonomous tests, so that they don't depend on each other, and when one fails, then we know exactly what failed.</p>
      </aside>
    </section>
            
<section>
  <h3>Page Object Overview</h3>
  <div style="float:left;width:50%;" class="centered">
  <img src="assets/images/PageModelExample.png" style="border:0; text-align:center; background:none;">
</div>
<div style="float:right;width:50%;" class="centered">
  <ul>
    <li>"Object Repository" </li>
      <li>Unique class per page</li>
        <li>Base classes can scale</li>
        <li>Test Code less brittle</li>
          </ul>
  </div>
  <aside class="notes">
<p>The idea with page objects, and again you may already know this if you've taken the Selenium 201 course, is that you want to abstract re-usable code into separate classes and create a object repository of Web UI elements that are associated with your Website</p>
<p>In other words you will have a Base Class where a lot of re-usable methods will exist such as a click, locator for elements, waits, drags, scrolls, typing, etc. etc., that you can scale across multiple pages rather than having to retype those selenium commands for each page object.</p>
<p>Also, you can have similar model for test cases too. In other words you can have all of your Desired Capabilities, and any other prerequisite tasks in a Base test class, in case you need to run parrallel tests or you want to scale those tests across multiple pages.</p>
  </aside>
</section>

<section>
  <h3><pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 60px;">PageBase</span></pre></h3>
  <ul>
    <p>Repeatable actions that scale across ALL pages</p>
    <ul>
      <li>Logins</li>
      <li>Mouse Clicks</li>
      <li>Keystrokes</li>
      <li>Waits/Pauses</li>
      <li>Button Presses</li>
    </ul>
  <aside class="notes">
<p>The primary reason you want to abstract re-usable actions into a Base Page is that your test code for each page object becomes cumbersome and hard to manage if you constantly have to re-type Selenium driver commands. Instead, it's much more useful to house these commands the base class, and then have each page object extend this class so that locating, and performing actions on UI elements becomes easier</p>
  </aside>
</section>

<section>
  <h3>Page Base Example</h3>
  <pre><code class="Java" data-trim contenteditable>
    public WebElement find (By locator) {
    return driver.findElement(locator);
}

public void clickOn (By locator) {
    find(locator).click();
  }

public String getText (By locator) {
    return find(locator).getText().toString();
}

public void typeString (By locator, String input) {
    findElement(locator).sendKeys(input);
  }
  </code></pre>
  
  <aside class="notes">
<p></p>
  </aside>
</section>

<section>
  <h3>Page Object</h3>
  <ul>
  <li>Extend the Base class</li>
  <li>Create constructor for intialization</li>
</ul>
  <pre><code class="Java" data-trim contenteditable>
  public class GuineaPigPage extends PageBase {
  ...
  public GuineaPigPage(WebDriver driver) {
    super(driver);
  }
}
  </code></pre>
  <aside class="notes">

    For each page we create a separate class that extends the base class. We also create a constructor to hold these initialized variables in memory. Then we go on to identify specific locators per page object UI Element. This helps us to re-use locators for multiple pages and also makes it easier to find and change a given locator if required.</aside>
</section>

<section>
  <h3>Page Object Example</h3>
  <pre><code class="Java" data-trim contenteditable>
 public class GuineaPigPage extends PageBase{

  public GuineaPigPage(WebDriver driver) {
    super(driver);
  }

  By commentBox = By.cssSelector("#comments");
  By yourComments = By.id("your_comments");

  public void getText() {
    typeString(commentBox, "Hello World");
  }

  public String readComment() {
    this.visibleWait(yourComments, 10);
    return getText(yourComments);
  }
  ...

  </code></pre>
  <aside class="notes">

    So here in this example we have the previous methods from our PageBase class and we pass the locators through in order to execute the commands on this Page Object. For example we have a method for typing keystrokes into UI form and we pass the commentBox locator along with the desired string value. Below that we have a method that reads the comments (along with a wait method) and returns the value.</aside>
</section>

<section>
  <h3>Page Object Best Practices</h3>
  <ul>
    <li>Class for each page</li>
    <li>Abstract re-usable code in base class</li>
    <li>Create base test classes</li>
    <li>Do NOT put assertions in action page objects</li>
  </ul>
  <aside class="notes">
<ul>
  <li>Each page of your website should have it's own page object which in turn is a class</li>
  <li>Re-usable commands belong in a base class, and each page object should extend the base class</li>
  <li>The same principles should apply to the test base class, in other words you have a test base class that holds setup methods, checkers, and setters, and you can have separate test classes for functional, or unit tests</li>
  <li>It's a bad practice to put assertions in a page objects, especially actionable page objects that are validating the results of your overall test. Nesting asserts in your page objects makes them less autonomous—even though it may be a good way to check that page objects are doing what they're supposed to, it's better to use a try catch and throw some sort of exception</li>
</ul>
  </aside>
</section>

    <section>
      <h3>Test Automation Frameworks</h3>
        <ul><p>Java Frameworks:</p>
          <li>JUnit</li>
          <li>TestNG</li>
        </ul>
        <ul><p>Other Frameworks:</p>
          <li>Python: <a href="https://github.com/saucelabs-sample-test-frameworks/Python-Pytest-Selenium"target="_blank">Py.test</a></li>
          <li>Ruby: <a href="https://github.com/saucelabs-sample-test-frameworks/Ruby-RSpec-Selenium"target="_blank">Rspec</a>, <a href=""target="_blank">Cucumber</a>,</li>
          <li>Javascript: <a href=""target="_blank">Mocha</a>, <a href="https://github.com/saucelabs-sample-test-frameworks/JS-Protractor-Selenium"target="_blank">Protractor</a></li>
        </ul>
          <aside class="notes">
          <p>Running tests in parallel can accelerate your team's development process and facilitate a continuous integration/continuous delivery pipeline. Sauce Labs provides many test frameworks with several scripts to demonstarte how to run tests in parallel. These scripts are set in an "AS-IS" state, meaning they're primarily function is to demonstrate the testing process and to provide a proof of concept within that framework.</p>
              </aside>
      </section>

    <section>
    <h3>WebDrivers and CI/CD</h3>
                    
      <p>Scaling Strategies (Jenkins example):</p>
        <ol>
          <li>Distribute builds using <a href="https://wiki.jenkins-ci.org/display/JENKINS/Distributed+builds"target="_blank">slave and master nodes</a></li>
          <li>Leverage Test Configuration options to <a href="https://wiki.saucelabs.com/display/DOCS/Test+Configuration+Options"target="_blank">distribute tests across nodes</a></li>
          <li>Use Selenium Factory to offload environment variables</li>  
          <li>Configure <a href="https://wiki.saucelabs.com/display/DOCS/Configuring+Jenkins+Matrix+Projects+with+Sauce"target="_blank">Matrix Projects</a></li>
        </ol>
        <aside class="notes">
<p>The capacity of your CI/CD workstation becomes unstable with more  WebDrivers in the pipe. You can distribute your builds across builds to save on thread counts, and you can also leverage test configuraiton options such as the Sauce On Demand browsers to offload passing environment variables into your test methods</p> <p>Late we will cover how to utilizie Selenium Factory class which is way to store all of your browser + Os combos in a helper class that is also offloaded by the Sauce plugin</p>
<p>Finally you can also configurea a Matrix project to reduce redundancy</p>
</aside>
        
</section>

  <section>
  <h3><pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 60px;">ThreadLocal</span></pre> and Parrallelizaiton</h3>
  <ul>
    <li>Set private variables via multithreading</li>
    <li>Allows each <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">Thread</span></pre> to execute same code with different variables
    <ul>
    <li>Useful tool for static data</li>
    <li>Requires configuration in Maven <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">pom.xml</span></pre></li>
    <li>Not-so useful for ambient data</li>
    <li>May cause headaches with single-threaded app servers (i.e. NGINX)</li>
  </ul>
</li>
  </ul>
  <aside class="notes">
ThreadLocal is particularly useful if you have static fields that should not be shared between threads such as the fields of the Desired Capabilities object. Also, be aware that correct teardown methods are a must when using threadlocal because due to thread_pools, your thread task may outlive the thread which can cause something known as threadleaks. Also, if you have an application server like NGINX that uses a single-thread event loop, it may cause a blocking operation (Nginx does have a thread pool option as well but it's sensitive to disk latency). So in short, know when to use ThreadLocal and when to Not use ThreadLocal
  </aside>
</section>

<section>
  <h3><pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 60px;">DataProvider</span></pre> Annotation</h3>
  <p>Execute parallel commands using an <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">Object Array</span></pre> or <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">HashMap</span></pre> for the data mapping</p>
  <pre><code class="Java" data-trim contenteditable>
    @DataProvider(name = "hardCodedBrowsers", parallel = true )
    public static Object[][] sauceBrowserDataProvider(Method testMethod) {
        return new Object[][]{
                new Object[]{"internet explorer", "11", "Windows 8.1"},
                new Object[]{"chrome", "41", "Windows XP"},
                new Object[]{"chrome", "54.0", "OS X 10.9"},
                new Object[]{"firefox", "27.0", "Windows 10"},
                new Object[]{"safari", "7.0", "OS X 10.9"},
                }
          ;
  </code></pre>

  <aside class="notes">
The data provider is a TestNG annotation that helps facilitate parralell execution by placing static values (such as your browser os combo) in a json object array or a HashMap
  </aside>
</section>


  <!--Advanced Page Object Lab-->
<section>
  <section data-state="lab"> 
      <h3>Lab 1.1: Creating the Base Page Class</h3>

      <ol>
        <li>In the Eclipse package explorer (left panel), open <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">sel301-java-testng-lab1</span></pre>.</li>
        <li>In the package manager, select <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">pages > GuineaPigPage.java</span></pre></li>
        <li>Create the new class: <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;"> PageBase.java</span></pre> in <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">pages</span></pre></li>
        <li>Abstract selenium <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">driver</span></pre> commands into public methods in <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">PageBase.java</span></pre> (next slide for details)</li>
      </ol>
    </section>
    <section data-state="lab"> 
      <h3>Lab 1.1: Creating the Base Page Class</h3>

      <ol>
        <li>Import the following packages into <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">PageBase.java</span></pre>:
        <pre><code class="Java" data-trim contenteditable>
package pages;
import org.openqa.selenium.By;
import org.openqa.selenium.InvalidElementStateException;
import org.openqa.selenium.WebElement;
import org.openqa.selenium.remote.BrowserType;
import org.openqa.selenium.WebDriver;
import org.openqa.selenium.support.ui.ExpectedConditions;
import org.openqa.selenium.support.ui.WebDriverWait;
          </code></pre></li>
        <li>Define a <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">WebDriver</span></pre> and a <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">BrowserType</span></pre> object:
        <pre><code class="Java" data-trim contenteditable>
public class PageBase {
  protected WebDriver driver;
  protected BrowserType browser;
          </code></pre></li>
      </ol>
    </section>

     <section data-state="lab"> 
      <h3>Lab 1.1: Creating the Base Page Class</h3>

      <ol>
        <li>Create a constructor method at the top of the script:
           <pre><code class="Java" data-trim contenteditable>
public class PageBase {
  protected WebDriver driver;
  protected BrowserType browser;

  public PageBase (WebDriver driver) {
    this.driver = driver;
  }
          </code></pre></li>
      </ol>
    </section>

    <section data-state="lab"> 
      <h3>Lab 1.1: Creating the Base Page Class</h3>

      <ol>
        <li>Convert driver commands from <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">GuineaPigPage.java</span></pre> into new methods in <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">PageBase.java</span></pre>:
           <pre><code class="Java" data-trim contenteditable>
###EXAMPLES###
  public WebElement findElement (By locator) {
    return driver.findElement(locator);
  }

  public void pressButton (By locator) {
    findElement(locator).submit();
  }

  public void clickOn (By locator) {
    visibleWait(locator, 10).click();
  }

  public String getText (By locator) {
    return findElement(locator).getText().toString();
  }

  public void typeString (By locator, String input) {
    findElement(locator).sendKeys(input);
  }

  public String getPageTitle () {
    return this.driver.getTitle().toString();
  }


          </code></pre></li>
      </ol>
    </section>

     <section data-state="lab"> 
      <h3>Lab 1.1: Creating the Base Page Class</h3>

      <ol>
        <li>Create a <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">visibleWait()</span></pre> method:
           <pre><code class="Java" data-trim contenteditable>
public WebElement visibleWait(By locator, Integer timeout) {
    timeout = timeout != null ? timeout : 10;
      WebDriverWait wait = new WebDriverWait(driver, timeout);
      return (WebElement) wait.until(ExpectedConditions.visibilityOfElementLocated(locator));
  }
}
          </code></pre></li>

          <li>Create a display checker method called<pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;"> isDisplayed()</span></pre>:
           <pre><code class="Java" data-trim contenteditable>
public Boolean isDisplayed (By locator) throws InvalidElementStateException {
    if(!findElement(locator).isDisplayed()) {
      throw new InvalidElementStateException("This web element is not displaying");
    } else {
      return true;
    }
}
          </code></pre></li>
      </ol>
    </section>
  </section>


    <section data-state="lab">
      <h3>Lab 1.2: Authenticate the Test</h3>
      <ol>
        <li>Ensure <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">GuineaPigPage.java extends PageBase.java</span></pre></li>
        <li>Open <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">TestBase.java</span></pre></li>
        <li>Enter your Sauce Labs credentials for the <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">"USERNAME"</span></pre> and <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">"ACCESS_KEY"</span></pre> variables.</li>
        <li>Note <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">ThreadLocal</span></pre> and what it tries to achieve in terms of initializing a thread of <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">WebDrivers</span></pre> and <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">SessionIds</span></pre></li>
        </ol>
        <aside class="notes"></aside>
      </section>

<section>
  <section data-state="lab">
      <h3>Lab 1.3: Setting the Page Object</h3>

        <ol>
          <li>Open <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">GuineaPigPage.java</span></pre> class in the <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">pages</span></pre> package and change the constructor:
          <pre><code class="Java" data-trim contenteditable>
###Before###
this.driver = driver;

###After###
super(driver);
          </code></pre></li>
          <li>Open <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">https://saucelabs.com/test/guinea-pig</span></pre> in a local browser and inspect the page</li>
          <li>Create locators for the hyperlink, send button, comment box, and comment result 
            <pre><code class="Java" data-trim contenteditable>
          By linkTitle = By.linkText("i am a link");
By submitBttn = By.xpath("//*[@id=\"submit\"]");
By commentBox = By.cssSelector("#comments");
By yourComments = By.id("your_comments");
          </code></pre></li>
          
          </ol>
        <aside class="notes">
<ul>
  <li></li>
  <li></li>
  <li></li>
  <li></li>
  <li></li>
</ul>
                    </aside>
                  </section>

<section data-state="lab">
      <h3>Lab 1.3: Setting the Page Object</h3>

        <ol>
          <li>Create page object methods in <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">GuineaPigPage.java</span></pre> using the extended methods in <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">PageBase.java</span></pre>:
          <pre><code class="Java" data-trim contenteditable>
###EXAMPLES###
  public void visit() {
    driver.get("https://saucelabs.com/test/guinea-pig");
  }

  public void clickLink() {
    clickOn(linkTitle);
  }

  public void pressSubmit() {
    pressButton(sendButton);
  }

  public void submitComment() {
    typeString(commentBox, "Hello World");
  }

  public String readComment() {
    return getText(yourComments);
  }


  public String readTitle() {
    return this.getPageTitle();
  }

  public String readText() {
    return getText(linkTitle);
  }
          </code></pre></li>          
          </ol>
        <aside class="notes">
<ul>
  <li></li>
  <li></li>
  <li></li>
  <li></li>
  <li></li>
</ul>
                    </aside>
        </section>
  </section>
<section data-state="lab">
      <h3>Lab 1.4: Setting the Test Methods</h3>

        <ol>
          <li>Open <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">GuineaPigTest.java</span></pre> class in the <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">test</span></pre> package and add the following lines underneath the comment that reads "<pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">//Instantiate page object</span></pre>":</li>
          <li><pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">linkTest</span></pre></li>
          <pre><code class="Java" data-trim contenteditable>
  GuineaPigPage page = new GuineaPigPage(driver);
    page.visit();
    page.clickLink();
    assertEquals(page.readTitle(), "I am another page title - Sauce Labs");
</code></pre>
<li><pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">commentTest</span></pre></li>
<pre><code class="Java" data-trim contenteditable>
  GuineaPigPage page = new GuineaPigPage(driver);
    page.visit();
    page.submitComment();
    page.pressSubmit();
    assertEquals(page.readComment(), "Your comments: Hello World");
</code></pre></li>
          
          </ol>
        <aside class="notes">
          <p>Now we need to instantiate our page object in our test, otherwise we can't use it to abstract the page services from our test suite</p>
          <p>In the the linkTest and commentTest methods, add the following code<p>
                    </aside>
                  </section>

<section data-state="lab">
      <h3>Lab 1.5: Wait! What happened?</h3>

        <ol>
          <li>Save and Run a Maven test; the <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">commentTest(s)</span></pre> should fail</li>
          <li>Check the console log in Eclipse, and note the<pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;"> NoSuchElementException</span></pre> errors</li>
          <li>Open <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">GuineaPigPage.java</span></pre> and create the following line in the <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">readComment()</span></pre> method</li>
          <pre><code class="Java" data-trim contenteditable>
            this.visibleWait(yourComments, 10);
</code></pre>
<li>Save and re-run the test. What are the results?</li>
          </ol>
        <aside class="notes">
<p>Our test failed because we didn't have an explicit wait for our comment data entry with the sendKeys directive. We can use the visibleWait method that we defined earlier in our page object so that we can avoid this thrown exception.</p>
                    </aside>
                  </section>




<!-- Writing Testable Code -->

<section data-background="rgb(226, 35, 26)">
    <h2>Writing Testable Code</h2>
      <aside class="notes"></aside>
      </section>

<section>
      <h3>Module Objectives</h3>
        <p>This module enables you to:</p>
          <ul>
          <li>Incorporate Developer feedback</li>
          <li>QA Engineer/tester is a 'first class citizen'</li>
          <li>Specify object identifiers in the source code to ease test automation</li>
          <li>Follow best locator strategy practices</li>
          </ul>
        <aside class="notes"></aside>
        </section>

        <section>
          <h3>Automation as a Project</h3>
          <ul>
          <li>Treat as a Software Development project</li>
          <li>End to End vs. Unit Testing</li>
        </ul>
          <aside class="notes">
Some of the biggest problems with QA or automation engineering is that there's a gap of knowledge or collaboration effort between the developer and the QA engineer. In order to alleviate a lot of problems that we will outline later, we need to ensure that the QA or automation engineer's test code is considered a first class citizen and treated equally important as the product code. It's important to establish this feedback loop with the developer in order to create alignment.
          </aside>
        </section>

  <section>
    <h3>Developer Feedback</h3>
    <ul>
      <li>Earlier in the Lifecycle</li>
      <li>Testing Pyramids</li>
      <li>Passing Tests vs. Testing Apps</li>
      <li>Avoid Duplication and ensure Cohesion</li>
    </ul>
   <div style="float:right;width:90%;padding-right:0px;">
    <img src="assets/images/DilbertTesting.jpg" style="border:0; text-align:center; background:none;">
  </div>
    <aside class="notes">
<p>So in order to create this feedback loop there are a few stratigies to employ. </p>
<ul>
<li>Test earlier in the lifecycle, meaning before or on commits. </li>
  <li>Avoid testing pyramids, we will talk a little bit about this later but generally if you're doing a crazy-amount of testing in the UI you're doing yourself a diservice.</li>
  <li>There's also this idea about metrics, and sometimes the goal of testing gets muddled when  you focus on 99% pass rate vs. actually writing meaningful tests.</li>
  <li> And finally it's paramount to ensure you're not committing duplicate code due to miscommunicaiton. This becomes increasingly dangerous if your test code and product code exist in the same repoistory.</li>
</ul>
    </aside>
  </section>

<section>
  <section>
    <h3>Duplication</h3>
    <p>If multiple groups own different tests, a natural divide will occur. Ways to mitigate this problem:</p>
    <ul>
      <li>Work Iteratively</li>
       <li>Become a "First-Class Citizen"</li>
      <li>Align with Business Analysts' stories</li>
      <li>Avoid the <a href="https://watirmelon.blog/2012/01/31/introducing-the-software-testing-ice-cream-cone/"target="_blank">Ice Cream Cone Anti-Pattern</a></li>
    </ul>
    <aside class="notes">
      So here we're echoing some sentiments we've previously mentioned but a few points worth mentioning here. The third bullet point is important because often times if we're talking about TDD (Test Driven Development) we can fall into this trap where we loose sight of the business needs that necessitated the feature in the first place. Now as far as the ice cream cone pattern goes in the next slide...
    </aside>
  </section>
  <section>
    <h3>Ice-Cream Cone</h3>
     <div style="float:left;width:40%;" class="centered">
  <img src="assets/images/softwaretestingicecreamconeantipattern.png" style="border:0; text-align:center; background:none;">
            <small>Image Courtesy of: <a href="https://watirmelon.blog/2012/01/31/introducing-the-software-testing-ice-cream-cone/" target="_blank">WatirMelon.Blog</a>
            </small>      
</div>
<div style="float:right;width:50%;" class="centered">
  <p></p>
  <h4>How did this happen!!?</h4>
  <ul>
    <li>Lack of Collaboration</li>
      <li>Too Many Owners (duplication)</li>
      <li>Testing at the 'Highest' Level </li>
      <li>Disagreement on Goals</li>
    </ul>
    <p></p>
  </div>

    
    <aside class="notes">
This happens when we test at the highest level, meaning exclusively in the UI. It could also occur if we have too many sepearate owners for separate code bases. In other words this QA Engineer owns testing for this feature, that QA Engineer owns testing for that feature and all test code exists in sepearate repositories from product. Developers work in silos insulated from QA Engineers.
    </aside>
  </section>

  <section>
    <h3>Ideal Testing Pyramid</h3>
     <div style="float:left;width:50%;" class="centered">
  <img src="assets/images/idealautomatedtestingpyramid.png" style="border:0; text-align:center; background:none;">
            <small>Image Courtesy of: <a href="https://watirmelon.blog/2012/01/31/introducing-the-software-testing-ice-cream-cone/" target="_blank">WatirMelon.Blog</a>
            </small>      
</div>
<div style="float:right;width:50%;" class="centered">
  <p></p>
  <h4>Steps to Fix Ice-Cream</h4>
    <ul>
        <li>Cross-role parings</li>
        <li>Story Kick-offs!</li>
        <li>Test at 'Lowest' Level
          <ul>
            <li>Shifting Left</li>
            <li><a href="http://fabiopereira.me/blog/2012/03/18/introducing-depth-of-test-dot/" target="_blank">Shallow DOT</a></li>
          </ul></li>
        <li>Shared (Veritcal) Metrics</li>
          </ul>
    <p></p>
  </div>
    <aside class="notes">
So how the heck do we fix this? One of the simpliest strategies is to have cross-role parings--where you have one QA/Automation Engineer per developer. This way the communicaiton channel or developer feedback loop is established early and forced via a buddy system. In terms of agile development it's important to hold team kickoffs to align all of the development goals around user stories. And finally we should test at the lowest level, in other words automated unit testing that are small, autonomous, and atomic. Some of the ways we can do this is by Shifting left which implies testing earlier in the dev cycle, and having a shallow DOT (depth of test)
    </aside>
  </section>
  <section>
    <h3>Depth of Test</h3>
    <p>Shifting Left depends on shallow depth of testing</p>
    <h4>Which layer is most important?</h4>
    <ul>
      <li>JS Layer</li>
      <li>Controller layer</li>
      <li>Domain model, validators, calculator</li>
      <li>Data Model and Repo</li>
    </ul>
    <aside class="notes">
To explain DOT, let's take an example application. Let's assume that it's a business app that used for business quotes and has several business validation rules. Before we test the entire application like it's a black box, we should break it into parts first. So if we abstract the app into layers we should have:
<ul>
  <li>JavaScript layer that communicates to server side using JSON</li>
  <li>Controller layer that has mandatory validators and quote pricing</li>
  <li>The domain model, the business rule validators, and the calculator class that generates the pricing</li>
  <li>And at the bottom you have the actual pricing data next to the code repository</li>
</ul>
<p>The easiest way to think of Depth of Test is to think of the terms origin, which derives from a photography term called depth of field. Which in a nutshell refers to the distance between the nearest and farthest objects that appear in focus in an image. If we take that to a literal translation of software development, depth of test refers to the distance between the nearest and farthest software components that receive a visit during test execution. Now a software component doesn't necessirly imply one class or one function, it could mean the entire pricing calculator in this example--which is crucial component for that app to work correctly. This is the essence of shallow testing, we're performing targeted unit testing on the core components of your applicaiton while performing minimal funcitonal tests at the UI level.</p>
    </aside>
</section>
</section>



  <section>
    <h3>Cohesion</h3>
    <ul>
      <li>Two teams, one codebase</li>
      <li>Maintainable test suite that respects the entire stack</li>
    </ul>
    <aside class="notes">
We've mentioned it several times already, but it doesn't matter how many teams you have. If they are a stakeholder in the project there should be a minimal amount of codebases. For example, two teams (A QA and Dev team), there should be one codebase. Extrapolating further on our concept of shallow testing, we should indeed have one maintainable test suite that respects the entire stack. Now the frequency of running these tests depends on how you manage the project. For example the afformentioned shallow unit tests can run on every commit whereas higher funcitonal tests need only run when something changes on the frontend.
    </aside>
  </section>


  <section>
    <h3>Mythical Coverage</h3>
    <center><img src="assets/images/codeCoverage_meme.jpg" style="border:0; text-align:center; background:none;">
    <p>Perfect is the enemy of great</p></center>

    <aside class="notes">
we talked a bit about focusing on metrics too much. To be honest, if you have a business policy that requires 99% code coverage I think you're org is probably broke. This will incentivize your devs and qa engineers to write tests just for the sake of writing tests.
    </aside>
  </section>

  <section>
  <section>
    <h3>Unit Testing Best Practices</h3>
    <div style="float:left;width:50%;" class="centered">
                   
    <ul>
      <li>Aim for 80% coverage </li>
      <li>Use broad but manageable data set</li>
      <li>Treat like source code</li>
      <li>Not designed for bug detection</li>
    </ul>
  </div>

  <div style="float:right;width:40%;padding-right:0px;">
    <img src="assets/images/testAllthings.jpg" style="border:0; text-align:center; background:none;">
  </div>
    <aside class="notes">
Instead, as a team, you should outline what are acceptable losses and where in terms of the layers of your application, and use a broad managbel data set to test various components of your application.
    </aside>
  </section>

<section>
  <h3>Small, Atomic, and Autonomous Testing</h3>
    <div style="float:left;width:10%;padding-right:5px;padding-bottom:10px;"><img src="assets/images/icons.png" style="border:0; text-align:center; background:none;">
    </div>
    <div style="padding-top:10px;"><p><strong>Small:</strong> Tests should be short and succinct.</p>
      <p><strong>Atomic:</strong> Tests should focus on testing a single feature.</p>
      <p><strong>Autonomous:</strong> Tests should be independent of other tests.</p>
      </div>
      <aside class="notes">
        <p>Short - If you have a test suite of 100 tests running concurrently on 100 VMs, then the time it will take to run the entire suite will be determined by the longest/slowest test case. Keeping your tests small ensures that your suite will run efficiently and provide you with results faster. </p>
        <p>Atomic - The test makes clear exactly what it is that you're testing. If the test fails, then you should also have a very clear idea of what needs to be fixed. </p>
        <p>Autonomous - Tests should not be dependent on the results of one test to run successfully. In addition, an autonomous test should use its own data to test against, and not create potential conflicts with other tests over the same data.  </p>
        </aside>
    </section>

    <section>
    <h3>Mocks, Stubs, and Spies</h3>
    <ul>
      <li><a href="https://martinfowler.com/articles/mocksArentStubs.html" target="_blank">Mocks</a> can reduce network latency by 'mocking' applicaiton backend</li>
      <li>Use <a href="https://techblog.polteq.com/en/test-doubles-creating-a-stub/" target="_blank">Stubs</a> to feed the test known data</li>
      <li><a href="http://junit.org/junit4/javadoc/latest/org/junit/Assert.html" target="_blank">Spies</a> are synomous with assertions, use them to validate tests</li>
    </ul>
    <p></p>

   <div style="text-align:center;">
            <small>Blog Post: <a href="https://saucelabs.com/blog/speed-up-selenium-with-application-mocks" target="_blank">Speed up Selenium with Application Mocks</a>
            </small>
          </div>
    <aside class ="notes">
An easier way to shift left and avoid testing through the UI each time, creating users for each test run which will increase test overhead, and worrying about persistent data surviving tests we can use mocks, stubs, and spies to simulate a lot of the functionality that is dependent upon data stores and external applications to run. This concept is way out of scope for this course, and deserves an entire course dedicated to teaching you the basics of simulating test data so instead of diving down the rabbit hole, there's a link here that further explains this concept and also provides code examples. After reading the explanations try and implement these concepts in your tests, or at the very least reduce some uncessary callouts to external applicaitons which will shorten your test suite uns
    </aside>
  </section>
</section>


<section>
    <h3>Functional Testing</h3>
    <ul>
      <li>Developer Accountability</li>
      <li>Test Build Feedback
        <ul>
          <li>Require functional test if frontend changed</li>
          <li>Ensures Build is clean when merged with master</li>
        </ul>
      </li>
    </ul>
    <aside class="notes">
Again, the higher level tests should not run as frequnetly as your shallow tests. When the tests do run, it's important to notify the developer or ensure accountablity in dev cycle, whether it's an exception handler or something at the Jenkins job notification level.
    </aside>
  </section>

<section>
  <h3>Location Strategy Practices</h3>
  <ul>
    <li>Avoid brittle, structure-based locators
    <ul>
      <li>DOM</li>
      <li>Xpath</li>
    </ul>
  </li>
      <li>Use attribute-based locators
        <ul>
          <li>ids</li>
          <li>Links</li>
          <li>CSS</li>
        </ul>
      </li>
        </ul>
  <aside class="notes">
I don't know where the argument currently lies persay but at Sauce Con 2017, the general consensus was that most people don't use XPath anymore and that you should be using ids whenever you can. If not, get tricky with your CSS locators (which we covered in Selenium 201 course), because although the learning curves might be steep, it will make you an automation rockstar. To show the brittleness of XPath's were' going to explore supplementing xpath for CSS locators in our next lab.
  </aside>
</section>

<!--Broken XPath Lab-->

<section data-state="lab">
      <h3>Lab 2.1: Brittle XPath</h3>

        <ol>
          <li>Open the local test page index2.html</li>
          <li>Inspect the "Send" button in the lower right corner of the screen</li>
          <li>Open <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">GuienaPigPage.java</span></pre> and uncomment the second <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">driver.get</span></pre> command:
          <pre><code class="Java" data-trim contenteditable>
          public void visit() {
    driver.get("https://saucelabs.com/test/guinea-pig");
    //driver.get("https://jtack4970.github.io/training-test-page-james/");
  }
          </code></pre>
          <li>Run the test, it should fail. What happened?</li>
          
          </ol>
        <aside class="notes">
<ul>
  <li>Create an ID for the submit button in the input tag</li>
  <li>Replace your locator with an ID rather than XPath</li>
  <li>Run the test to resolve the location issue</li>
  <li>Re-open index2.html and move the submit button to higher in the DOM</li>
  <li>Re-run the test. Does it still pass?</li>
</ul>
                    </aside>
</section>

<section data-state="lab">
      <h3>Lab 2.2: CSS, My Favorite &#60;type&#62; </h3>

        <ol>
          <li>Open <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">GuineaPigPage.java</span></pre> and navigate to the locators</li>
          <li>Replace the <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">xpath</span></pre> selector with a <pre style="display:inline; color:rgb(87,193,232);"><span style="font-size: 30px;">CSS</span></pre> attribute selector:
<pre><code class="Java" data-trim contenteditable>
By.cssSelector("input[type*=\"submit\"]");
</code></pre></li>
          <li>Run a Maven test</li>
          <li>The instructor will move the submit button to a different position in the DOM</li>
          <li>Re-test to see if the test still passes</li>
          
          </ol>
        <aside class="notes">
CSS locators are my favorite locator type because they're so flexible. We can use various css selectors to fine-tune our location strategy. One of the most versatile is an attribute selector. This is especially useful if your element has specific attributes but no class or id selector. This way we can zero in specific style or type attribute values. Hopefully after we replace this xpath selector, and I move the button to a different position int he DOM, the test won't break.
                    </aside>
</section>


<!-- Building a CI/CD Pipeline and Test Process -->
<section data-background="rgb(226, 35, 26)">
    <h2>The CI/CD Pipeline and Test Process</h2>
      <aside class="notes"></aside>
      </section>
<section>
      <h3>Module Objectives</h3>
        <p>This module enables you to:</p>
          <ul>
          <li>The importance of "Shift Left" testing</li>
          <li>Create a pull request build and test in isolation</li>
          </ul>
        <aside class="notes"></aside>
        </section>

        <section>
                  <h3>Overview of CI/CD Pipeline</h3>
                  <img src="assets/images/sauceCI2.png" style="border:0; text-align:center; background:none;">
                    <p style="text-align:center;">Continuous Integration/Continuous Development</p>
                    <aside class="notes">
                      <p>Sauce Labs' value as a time saver is apparent even in its role in Continuous Integration and Delivery. </p>
                      <p>Traditionally, testing and QA are bottlenecks for application delivery and release. Writing automated tests, maintaining testing infrastructure, painful manual testing, all consume huge amounts of time. The work is never done either, because the product is always changing.</p>
                      <p>Sauce Labs takes away those worries though. With Selenium and Appium testing, we remove the barrier of time consuming test writing, and with Sauce Labs itself, we remove the need to have a propietary infrastructure. Sauce Labs provides the infrastructure for you, allowing you to test on a variety of platforms in a speedy manner. So you can focus on development, and releases, and leave the testing to Sauce Labs.</p>
                      <p>Sauce Labs reduces the pain of testing, so that instead of traditionally waiting until the end of the development life cycle to test, you can test iteratively, as you go through each step of development.</p>
                    </aside>
                </section>
                <section>
                  <h3>JIRA Intergration</h3>
                  <!-- left column-->
                    <div style="float:left;width:50%;" class="centered">
                  <p>Use Cases:</p>
                  <ul>
                    <li>Track and Share Test Results</li>
                    <li>Match Builds with a Sprint</li>
                    <li>Attach Test Assets to a JIRA Issue</li>
                    <li>Bridge gap between Dev and QA</li>
                    </ul>
                  </div>
                     <!-- right column-->
                    <div style="float:right;width:50%;padding-right:0px;">
                  <img src= "assets/images/atl_Logo.png" style="border:none; background:none; width:80%">
                    </div>
                </section>

                <section>
                  <h3>Available CI Plugins</h3>
                  <ul>
                    <li>TeamCity</li>
                    <li>Visual Studio</li>
                    <li>Bamboo</li>
                    <li>Bitbucket Pipelines</li>
                    <li>Jenkins</li>
                    </ul>
                    <div align="middle">
                  <img src= "assets/images/plugins.png" style="border:none; background:none; width:90%">
                    </div>
                </section>
                <section>
              <h3>Jenkins Plug-In</h3>
              <p>Sauce Connect can leverage Jenkins CI/CD pipeline using Sauce OnDemand CI Plugin</p>
              <ul>
              <li>Requires installation and configuration of Jenkins</li>
              <li>Manually test before committing to repo</li>
            </ul>
              <div align="middle">
                  <img src= "assets/images/Jenkins.png" style="border:none; background:none; width:35%">
                    </div>
              <aside class="notes">  Today we are going to cover the Jenkins plugin exclusively. Including Sauce Connect and SauceLabs by extension as part of the build process in Jenkins can contribute to the effectivness of your QA and product rollout or deployment process. However it's worth mentioning that before you begin testing in Jenkins, it's a good idea to ensure the manually tests are running correctly in Sauce Labs first.</aside>
            </section>
                <section>
                  <h3>Benefits of CI Plugins</h3>
                  <ul>
                    <li>User interface to pass environment variables to tests</li>
                    <li>Automate launch and teardown process for Sauce Connect Proxy</li>
                    <li>Handle reporting throught SaucleLabs Test Publisher</li>
                  </ul>
                </section>

                 <section>
                  <section>
                    <h3>Installing Sauce OnDemand</h3>
                    <ul><p>Install Sauce OnDemand plugin through the Jenkins Admin page<p> 
<li>Click "Manage Jenkins"</li>
<li>Click "Manage Plugins"</li> 
<li>Click the "Available" tab</li>
<li>Search and select Sauce OnDemand Plugin</li> 
<li>Download and install after restart</li>
</ul>
<aside class="notes">The Sauce OnDemand plugin allows user to populate environment variables on the Jenkins server that can be used in tests (e.g. Sauce USER and ACCESS_KEY) The plugin file is fairly large, so download may take several minutes.  
In the plugin installation dialog, select Restart Jenkins when installation is complete and no jobs are running.</aside>
                  </section>
                  <section>
                    <h3>Configuring OnDemand</h3>
                    <ul>
                      <li>Pass Environment Variables</li>
                      <li>Set Authentication</li>
                      <li>Set Desired Capabilities</li>
                      <li>Set Jenkins Capabilities</li>
                      <li>(Optional) Change Binary Locations</li>
                      <li>(Optional) Enable Sauce Connect CLI options</li>
                    <aside class="notes">The Jenkins plugin provides an interface for storing your Sauce Labs authentication credentials as environment variables on the Jenkins server, which is one of our best practices for testing with Sauce. This allows you to reference your credentials without having to hardcode them into your tests, and because the plugin manages authentication at the global level, you can have multiple jobs running at the same time that use these credentials. </aside>
                  </section>
<!-- Sauce onDemand Lab -->
                
                </section>
                  <section>
                  <h3>Passing Environment Variables</h3>
<pre><code class="zsh" data-trim contenteditable>
                        SAUCE_USERNAME # user used for OnDemand
SAUCE_ACCESS_KEY # key used for OnDemand user
SAUCE_ONDEMAND_BROWSERS # JSON string representing Desired Browsers
SELENIUM_HOST # Host address of Selenium server
SELENIUM_PORT # Port address of Selenium server
                    </code></pre>
                    <aside class="notes">These are some of the variables used for the OnDemand Jenkins plugin, We can specify the details of the actual Selenium grid by using SELENIUM_HOST and PORT. As well as the Sauce Access_key and Username to allow us to send REST calls during the build process.</aside>
                  </section>
<section>
  <h3>Selenium Factory</h3>
  <p>To Enable:</p>
  <ol>
  <li>Declare dependencies in Maven project</li>
  <li>Reference Sauce Labs Maven repository</li>
  <li>Instantiate driver in script like so:</li>
</ol>
  <pre><code class="zsh" data-trim contenteditable>
    WebDriver webDriver = SeleniumFactory.createWebDriver();
  </code></pre>
   <div style="text-align:center;">
            <small>Source Code: <a href="https://github.com/infradna/selenium-client-factory" target="_blank">Selenium Client Factory</a>
            </small>
          </div>
  <aside class="notes">
<p>If you're using Sauce on Demand browsers, the Selenium factory implementation will handle referencing any browser + OS combo, environment variables, and/or system properties set by the CI plugin. To use it you simply have to construct a webdriver and reference the class, however in order for it to work correctly you have to edit the xml file of your Maven build, such as referencing any dependencies in the Maven Project, and also ensure you your project is refrencing the the sauce labs maven repository</p>
<p>There is a link to the source code at the bottom of this page, if you wish to play around with optimize your CI builds using SauceLabs. Again, the use case here is that the CI server will handle the environment varaibles while you can abstract these variables from your actual build configuration, this wil lmake the your test code less cluttered and easier to manage</p>


  </aside>
</section>
                  <section>
                    <h3>Setting Authentication</h3>
                    <p>Example:</p>
                    <pre><code class="zsh" data-trim contenteditable> 
                    WebDriver driver = new RemoteWebDriver(
new URL("https://"+System.getenv("SAUCE_USERNAME")+":"
+System.getenv("SAUCE_ACCESS_KEY")+"@ondemand.saucelabs.com:443/wd/hub",
            desiredCapabilities);
          </code></pre>
          <aside class="notes">In this example we're setting the authentication via our selenium script and referencing the environment variables we stored in Jenkins the using the Sauce OnDemand plugin.</aside>
        </section>
                  <section>
                    <section>
                      <h3>Set Desired Capabilities in Test Script</h3>
                      <p>Configure Variables in Test Scripts:</p>
                    <pre><code class="zsh" data-trim contenteditable>                        desiredCapabilities.setBrowserName(System.getenv("SELENIUM_BROWSER"));
desiredCapabilities.setVersion(System.getenv("SELENIUM_VERSION"));
desiredCapabilities.setCapability(CapabilityType.PLATFORM, System.getenv("SELENIUM_PLATFORM"));
                    </code></pre>
                    <aside class="notes">Next we can set the capabilites again using the stored environment variables such as Selenium host, version, and even the desired browsers</aside>
                  </section>
                  <section>
                    <h3>Setting Capabilities for Jenkins</h3>
                    <p>Configure a SAUCE_ON_DEMAND env variable if you plan on selecting multiple OS/browser combinations for your parrallel tests</p>
                    <p>Configure SELENIUM_PLATFORM, SELENIUM_VERSION, and SELENIUM_BROWSER for a single operating test.</p> 
                  <aside class="notes">So thus far we've set indivudal variables whenever we want to run one build with one platform/selenium host and port combo. But what if we want to run parrallel tests using different browser and OS combos? Here is where we use Sauce_On_demand variable where we specify these details in a list (next slide shows example).</aside>
                  </section>
                  <section>
                    <h3>Example</h3>
                    <pre><code class="zsh" data-trim contenteditable> 
                    [
    {
        "platform":"LINUX",
        "os":"Linux",
        "browser":"firefox",
        "url":"sauce-ondemand:?os=Linux&browser=firefox&browser-version=16",
        "browserVersion":"16"
    },
    {
        "platform":"VISTA",
        "os":"Windows 2008",
        "browser":"iexploreproxy",
        "url":"sauce-ondemand:?os=Windows 2008&browser=iexploreproxy&browser-version=9",
        "browserVersion":"9"
    }
]
</code></pre>
                    <aside class="notes">Here in our Sauce_on_demand varibable we're storing data for two separate platforms, and the inclusion of the Sauce_on_demand variable allows Jenkins to run these tests in parrallel during the build process</aside>
                  
                  </section>
                </section>
                  <section>
      <section>
        <h3>Sauce Connect Proxy™</h3>
          <p>Tunneling app that establishes a secure connection between local machine and Sauce Lab VM.</p>
            <div style="position:center;float:left;width:50%;"class="centered">
            <ul>
              <li>Alternative to whitelisting IPs</li>
              <li>Stablizes network connection</li>
            </ul>
            </div>
          <div style="position:center;float:right;width:50%;"class="centered">
            <img src="assets/images/SC_logo.png" style="float:right;border:none; background:none; width:60%">
          <p style="text-align:center;">
            <small>Documentation: <a href="https://wiki.saucelabs.com/display/DOCS/Sauce+Connect" target="_blank">Sauce Connect Proxy</a>
            </small>
          </p>
          </div>

        <aside class="notes">Sauce Connect Proxy™ is a tunneling VM service (proxy server) that allows you and your teams to securely test applications behind your firewall. Sauce Connect is technically not required to run tests with Sauce Labs unless the website or application is not publicly accessible.  Sauce Labs recommend to enlist the aid of a network engineer to install Sauce Connect due to the complications of network architectures.</aside>
        </section>
    
                
      <section>
          <h3>Monitoring Tunnels</h3>
            <ul>
              <li>Choose the "Tunnels" tab to view "Active Tunnels"</li><li>Display is list format with <i>Session ID</i> and <i>Host</i></li>
            </ul>
              <div align="middle"><img src="assets/images/Firefox3.png" style="border:none; background:none; width:90%">
              </div>
          <aside class="notes">When you choose the "tunnels" tab in the "active tunnels" tab in the SauceLabs UI, what you're actually looking at is the tunnel VM that was spun up by your SauceLab client. These Vms are emphemeral by nature, meaning once the test is completed, the Sauce Connect Client will execute a teardown proccess that will gracefully shut these VMs down. The Tunnel Vms are represented in this tab by their Session IDs and Host ID</aside>
      </section>

    <section>
        <h3>SC Proxy Best Practices</h3>
          <p>Security/Networking</p>
            <ul>
              <li>Designated Server</li>
              <li>Firewall Rules</li>
              <li>Intrusion Detection</li>
              <li>Persistent tunnel(s) or HA tunnels?</li>
              <li>Work with Network Admin</li>
            </ul>
            <p>Concurrency</p>
              <ul>
              <li>30 Per Tunnel</li>
              </ul>
          <aside class="notes"><p>so just for a rewview of the Sauce Connect Proxy best practices</p><ul>
          <li>Use a designated Server for Sauce Connect Proxy client</li>
          <li>Asses firewall rules so Sauce Client ONLY has access to the specific host it's trying to test</li>
          <li>Configure Intrusion Detection on Sauce Connect Proxy logs so that we know the correct interception is happening rather than an alternative or spoofed interception</li>
          <li>In another course we cover in detail how to set up a highly available tunnel configuration. What this means is that you'll have a group of tunnels that have the exact same id and Sauce Connect can load balance across those tunnels depending on the amount of concurrent tests you have running. This is more useful for your DevOps or Network Admin guys, but if you're interested in how to set it up, stay after class and I can show you some of the flags and how they work</li>
          <li>Finally, whether you're using a persistent or pooled tunnels, to maintain performance, keep the amount of conncurrent connections per tunnel to 30 or less</li>
        </ul>
      </aside>
    </section> 

     <section>
                    <h3>Configure SC Launch and Teardown</h3>
                    <ol>
                      <li>Extract SC binary</li>
                      <li>Change Global Default location</li>
                      <li>Change Per-Project Default location</li>
                      <li>Set SC Command Line Options</li>
                      <li>(Optional)Set Unique Tunnler Ids</li>
                    </ol>
                    <aside class="notes"> 
Do not worry if your Jenkins server is behind a firewall because the Jenkins plugin for Sauce automatically installs Sauce Connect, but you will need to configure your project to use it. There are also global and per-project configuration options for Sauce Connect. The first step to running Sauce Connect with Jenkins is to enable it under the build environment settings under Sauce ondemand Support. There will be a checkbox that asks you to enable Sauce Connect. If the checkbox is selected, Sauce Connect will launch a new tunnel everytime you run a Jenkins build. Note that if you do run Sauce Connect then the Selenium HOST and PORT environment variables need to change to loclahost:4445</aside>
                  </section>
  </section>

  <section>
                    <h3>Marking Tests in Jenkins</h3>
                    <ul>
                      <li>Navigate to the "Post-Build Actions."</li>
                      <li>Select "Run Sauce Labs Test Publisher."</li>
                      <div align="middle">
                  <img src= "assets/images/post-build.png" style="border:none; background:none; width:40%">
                    </div>
                    <aside class="notes">Once we've set those two environment variables and also set them in our test script, we can send the Jenkins build results to the Sauce Labs Test Publisher. Howerver, if you did not configure your build capability, or if you set the incorrect JOB_NAME and BUILD NUMBER in the previous step this option will appear grayed out like you see it here.</aside>
                  </section>

                  <section>
                    <h3>Pass Session ID to Jenkins</h3>
                    <p>Sauce plugin parses test results file based on JOB_NAME</p>
                    <pre><code class="zsh" data-trim contenteditable>
                    SauceOnDemandSessionID=session_id job_name=some_job_name
                    </code></pre>
                    <p>Obtain session ID and ouptut to Jenkins via stdout</p>
                    <pre><code class="zsh" data-trim contenteditable>
                      private void printSessionId() {
 
String message = String.format("SauceOnDemandSessionID=%1$s\ 
job-name=%2$s",(((RemoteWebDriver) driver).getSessionId()).toString(),\
"some job name"); System.out.println(message);
                    }
                    </code></pre>
                    <p>
                    <aside class="notes">As part of the post-build activities, the Sauce plugin will parse the test result files in an attempt to associate test results with Sauce jobs. It does this by identifying lines in the stdout or stderr that have this format:

                    The session id can be obtained from the RemoteWebDriver instance and the job-name can be any string, but is generally the name of the test class being executed.
To make sure that your test results and Sauce jobs are associated properly, you need to output the session id to stdout. For example, this is the code you would use to output the session id to the Java stdout. </aside>
                  </section>

                  <section data-state="lab">
       <h3>Lab 3.1: Configure Sauce OnDemand™ Plugin</h3>
                  <ol>
                    <li>Create a new project on Jenkins (should be listening on localhost:8080)
</li>
                    <li>Configure a Build in Jenkins</li>
                    <li>Enable Sauce OnDemand and Sauce Connect as a build step</li>
                    <li>Enable Test Publisher</li>
                  </ol>
                  <aside class="notes">
                    <ol>
                      <li>Create a new project on Jenkins (should be listening on localhost:8080)
</li>
                      <li>Choose Configure in Jenkins Build
</li>
                      <li>Change the Source Code Management to this address: https://github.com/saucelabs-training/Java-TestNG-Selenium-Jenkins
</li>
                      <li>Enable SauceLabs Support in the Build Environment</li>
                      <li>Choose at least two platforms for desired capabilities in the Sauce Labs Options</li>
                      <li>Enable Sauce Connect checkbox</li>
                      <li>Invoke a top-level Maven targets as another build step. For example

Maven version 3.3.9, Goals = clean, test;</li>
                      <li>Set the Test Publisher as a post action build step</li>
                      <li>Run the build in Jenkins, then view the test results in SauceLabs.com</li>
                    </aside>
                  </section>

      <section>
        <section>
        <h3>Testing in Isolation</h3>
        <ul>
          <li>"Gate" master/trunk</li>
          <li>Relegate Accountability Criteria (A.C.) to feature branches
            <ul>
              <li>Integrates enforcement mechanism</li>
            </ul></li>
          </li>
          <li>Accountability</li>
        </ul>
        <aside class="notes">
          <p>So generally the point of unit tests is to reduce the scope of the SUT into a small subset that can be tested in isolation. This way we can reduce the amount of variables that may affect results. A good way to achieve this without screwing up your code base is to gate your branches via testing on commits and merges. That way any feature that's in trunk revision goes through proper compliance before being merged with the master branch. We'll talk a little bit later about Pull request builds to illustrate this. The benefit of setting your projects up this way is that it creates, not only a built in feedback loop between QA and Dev, but it also enforces quality commits rather than policing your devs</p>
        </aside>
      </section>
      
      <section>
        <h3>Commit/Merge on Nightlys</h3>
        <p>Drawbacks:</p>
        <ul>
          <li>Bad commits cause wasted rollbacks</li>
          <li>Gap in feedback loop</li>
          <li>Too reactive i.e. policing build</li>
          <li>Time to fix is expensive</li>
        </ul>
        <center><img src= "assets/images/Basic_build.png" style="border:none; background:none; width:60%"></center>
        <aside class="notes">
          The old school way of doing this is to commit on nightlys, however this comes with some drawbacks.
          <ul>
            <li>It can create too much revision and reactionary rollbacks, which costs time and money</li>
            <li>May not be aware until the next day so the feedback loop is widened</li>
            <li>Again, it forces people to notify devs that the commited bad code and also it takes time to identify who broke it. Plus ya know, there's that whole public shaming aspect where as if the testing and accountability structure was built in, the shame would be isolated</li>
            <li>lastly, it's a pain to fix in terms of time, money, and realignment across the team</li>
          </ul>
        </aside>

      </section>

      <section>
        <h3>Pull Request Builds</h3>
        <p>Process:</p>
        <ol>
          <li>Pull Request against isolated build</li>
          <li>Jenkins job leverges Sauce Lab test code, provides feedback to developer</li>
          <li>Passed tests marked 'safe' and merged with QA build</li>
        </ol>
        <center><img src= "assets/images/PR_Build.png" style="border:none; background:none; width:60%"></center>
         <aside class="notes">
<p>If we're trying to avoid rollbacks, costly feedback loops, and public shame, we can create an isolated build used for validation and testing</p> 
<p>Once a commit is marked as 'safe' and with no merge conflicts, we can push it to the master branch</p>
<p>We can also leverge Sauce Labs here to have an external system run the tests on the hosted grid, along with Jenkins to build and publish test results.</p>
         </aside>
      </section>

      <section>
        <h3>Jenkins Trigger</h3>
        <ul>
          <li>Create Test Automation as a build step with Sauce OnDemand plugin</li>
          <li>Triggers on every pull request</li>
          <li>If tests pass will automatically merge with testing build</li>
        <aside class="notes">
          In the example I'm about to show you we use a GitHub hook into Jenkins that triggers off a build on every pull request. Jenkins will run a few shell scripts that deploy an isolated build of the app into a docker container, run tests, check for conflicts and publish test results from Sauce. After the merge occurs we can run another job to merge the branches and deploy to production
        </aside>
      </section>

      <section>
        <h3>Further Accountability Criteria</h3>
        <p>Build requirements upon pull request approval/merge:</p>
        <ul>
          <li>Unit Test must pass</li>
          <li>All Functional Tests must pass</li>
        </ul>
        <aside class="notes">
We want two types of tests to occur on every pull request.
<ul>
  <li>Our shallow unit tests, which if failed or don't pass coverage, will cause the build to fail</li>
  <li>Second, we want a functional test to only occur if something on the frontend changes, that way we can reduce excessively testing the UI</li>
</ul>
        </aside>
      </section>
</section>
      
  <section>
        <h3>'Shift Left' Testing</h3>
          <ul>
          <li>Traditional: Concentrates on unit + integration testing</li>
          <li>Incremental: Abstracted, frequent development testing</li>
          <li>Agile/DevOps: Aligns with 'TDD' framework, test plan for each 'sprint'</li>
          <li>Model-Based: Begins earliest in cycle i.e. design and architecture models</li>
        </ul>
        <aside class="notes">
We've talked about shifting left throughout the day but here are a few specific models on how to approach the topic.
<ul>
  <li>Traditional V model of shift-left testing concentrates on shallow unit testing combined with integration testing. It comes under criticism because it implies a strict waterfall pattern of development which can create bottlenecks. However pushing the test to earlier in the cycle is still beneficial, even in a waterfall development pattern </li>
  <li>Incremental, is a little closer to agile testing in that it implies iterative testing to coincide with frequent code pushes</li>
  <li>Agile/DevOps aligns perfectly with what we've been talking about today. Code pushes are done in week-long or bi-weekly sprints, and testing is treated like part of the software development process</li>
  <li>Model based is a little newer and is contingent upon executable requirements, in other words: waiting until software exists in order to begin testing causes a delay... so this form of testing focuses on the most crucical architectural or design methods with regards to software development and begins testing continously and immediately</li>
</ul>
<p>These four models can show the historical progression of shift left testing, and it's clear that in the future testing and development will become so symbotic that they'll be almost identical in terms of importance and execution.</p>
        </aside>
      </section>

     

    <section>
  <h3>Test Run Best Practices</h3>
  <ul>
    <li>Avoid Brittle Test Locators</li>
    <li>Avoid Duplication</li>
    <li>Use Breakpoints</li>
    <li>Separate Functional Tests from Performance Tests</li>
  </ul>
  <aside class="notes">
This is review for test run strategies
<ul>
  <li>avoid xPath or other brittle selectors</li>
  <li>Increase cohesion within your team in order to avoid duplication</li>
  <li>When debugging, use breakpoints in your code so that you can pinpoint when junk hit's the fan</li>
  <li>Separate functional tests for frontend changes, and periodically run performance tests against your builds to compare results--this way you might be able to identify network issues, or client server roadblocks</li>
</ul>
  </aside>
</section>


  <section>
    <section data-state="lab" data-transition="none">
      <h3>Lab 4.1: Angular PR Build Demo</h3>
      <center><img src= "assets/images/PRBuildDemo0.png" style="border:none; background:none; width:100%"></center>
</section>
<section data-state="lab" data-transition="none">
      <h3>Lab 4.1: Angular PR Build Demo</h3>
      <center><img src= "assets/images/PRBuildDemo1.png" style="border:none; background:none; width:100%"></center>
</section>
<section data-state="lab" data-transition="none">
      <h3>Lab 4.1: Angular PR Build Demo</h3>
      <center><img src= "assets/images/PRBuildDemo2.png" style="border:none; background:none; width:100%"></center>
</section>
<section data-state="lab" data-transition="none">
      <h3>Lab 4.1: Angular PR Build Demo</h3>
      <center><img src= "assets/images/PRBuildDemo3.png" style="border:none; background:none; width:100%"></center>
</section>
<section data-state="lab" data-transition="none">
      <h3>Lab 4.1: Angular PR Build Demo</h3>
      <center><img src= "assets/images/PRBuildDemo4.png" style="border:none; background:none; width:100%"></center>
</section>
</section>

                  <section data-state="lab">
      <h3>Lab 4.2: Angular PR Build Demo</h3>
<p>Build Steps:</p>
        <ol>
          <li>Add Feature to App</li>
          <li>Push to trunk and create pull request</li>
          <li>Jenkins jobs kickoff, resolve test errors</li>
          <li>Re-push and view Jenkins Console + SauceLabs tests</li>
          <li>Merge Branches</li>
          <li>Deploy to Production</li>
          </ol>
          <p></p>
          <div style="text-align:center;">
            <small>Project Repo: <a href="https://github.com/saucelabs-training/selenium301-demo" target="_blank">Angular PR Build</a>
            </small>
         
          </div>
       
                  </section>
                

<!-- Test Data Management -->

<section data-background="rgb(226, 35, 26)">
    <h2>Test Data Management</h2>
</section>

<section>
      <h3>Module Objectives</h3>
        <p>This module enables you to:</p>
          <ul>
          <li>Identify TDM strategies</li>
          <li>Implement an automated TDM solution</li>
          </ul>
        <aside class="notes"></aside>
        </section>

<section>
  <h3>TDM Use Cases</h3>
  <ul>
    <li>Regulatory Compliance</li>
    <li>Quality Assurance</li>
    <li>Data Coverage</li>
  </ul>
</section>

<section>
  <h3>TDM Strategies</h3>
  <ul>
    <li>SQL Queries</li>
    <li>Flat File Solutions:</li>
    <ul>
    <li>JSON Mappings</li>
    <li>XML configs</li>
    <li>.csv, .pdf</li>
  </ul>
  </ul>
</section>

<section>
  <h3>TDM — Functional Testing</h3>
  <p>Key Tenets:</p>
  <ul>
    <li>Environment Size</li>
    <li>Requirements Gathering</li>
    <li>Fesability Check</li>
    <ul>
    <li>Regression Test</li>
    <li>A/B Test (versioning/build testing)</li>
  </ul>
  </ul>
</section>

<section>
  <h3>TDM — Automation Testing</h3>
  <ul>
    <li>Automation of Test Data</li>
    <li>Tooling vs. Testing Frameworks</li>
    <li>Pull Request Builds</li>
    <ul>
    <li>Executed on Nightlys</li>
    <li>Combines Unit and Functional Tests</li>
    <li>Data Coverage/Integrity as a CI/CD process</li>
  </ul>
  </ul>
</section>

<section>
  <h3>CRUD Flow</h3>
  <p>Arrange test data as meaningful end-user behavior</p>
  <ul>
    <li>CREATE</li>
    <li>READ</li>
    <li>UPDATE</li>
    <li>DELETE</li>
  </ul>
  <aside class="notes">
<p>
Try to combine scenarios for meaningful end-user behaviors. For example, let’s assume that you are testing a WordPress blogging application (create blog post, view the blog post, verify visitors, view by geography, delete the post, etc). If we logically group the end-user actions for that persona (i.e., author) and group them in Create, Read, Update and Delete flow, the data needed for the next step (Read) is likely created by the previous step (Create). We might end up testing a larger flow at the same time that necessary data is generated by the application part of the process. Data necessary for Create would have been created by the previous workflow. We don’t run into the stale data sitting in the system or data management issues where code refactoring expected a new field in the dataset, but we didn’t get a chance to update the test data generation script. In addition, if each one of the actions (Create, Read, Update and Delete) is an independent scenario, potentially some steps are repeated (i.e., launching the browser, navigate to website, login, navigate to posts page, etc). By forming CRUD flow, repeated steps are optimized, and as a result, tests complete faster.
</p>
  </aside>
</section>

<section>
  <h3>Service Virtualization</h3>
  <p>When trying to standup matching environments, use tools to simulate services</p>
  <aside class="notes"></aside>
</section>

<section>
  <h3>App Utilities vs. Test Framework</h3>
  <p>Testing the app vs. unit testing</p>
  <p>Functional vs. Feature-focus</p>
  <aside class="notes"></aside>
</section>

                  <!--<section data-state="lab">
      <h3>Demo 4:</h3>

        <ol>
          <li></li>
            <ul>
              <li></li>
              <li></li>
              <li></li>
            </ul>
          </li>
          
          </ol>
        <aside class="notes">
<ul>
  <li></li>
  <li></li>
  <li></li>
  <li></li>
  <li></li>
</ul>
                    </aside>
                  </section>-->

                 

                 <section>
                  <h3>Further Information</h3>
                  <li><a href="https://wiki.saucelabs.com/display/DOCS/Sauce+Connect+Proxy" target="_blank">Sauce Connect Documentation</a></li>
                  <li><a href="https://wiki.saucelabs.com/display/DOCS/The+Sauce+Labs+REST+API" target="_blank">REST API documentation</a></li>
                  <li><a href="https://wiki.saucelabs.com/display/DOCS/The+Sauce+Labs+Cookbook+Home" target="_blank">Sauce Labs Documentation</a></li>
                  <li><a href="https://github.com/saucelabs-sample-scripts" target="_blank">Sauce Labs Sample Test Scripts</a></li>
                  <li><a href="https://github.com/saucelabs-sample-test-frameworks" target="_blank">Sauce Labs Sample Test Frameworks</a></li>
                  <li><a href="https://wiki.saucelabs.com/display/DOCS/Using+Sauce+Labs+with+Continuous+Integration+Platforms" target="_blank">CI/CD Platform Documentation</a></li>
                  <aside class="notes"></aside>
                 </section>

                 <section>
                   <h3>Q&A</h3>
                   <li><a href="http://bit.ly/28NgER3" target="_blank">Survey!</a></li>
                   <li>Support: <a href="mailto:help@saucelabs.com" target="_top">help@saucelabs.com</a></li>
                   <aside class="notes"></aside>
                 </section>

            </div>


		</div>

      <script src="lib/js/head.min.js"></script>
	  <script src="js/reveal.js"></script>

	  <script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
                slideNumber: true,
				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
          			{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'lib/js/jquery-2.2.4.min.js'},
                    { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'plugin/external/external.js', condition: function() { return !!document.querySelector( '[data-external]' ); } },
                    { src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

            Reveal.addEventListener( 'slidechanged', function( event ) {
//            console.log(event.currentSlide.getAttribute("data-state"))
// if we're on a lab slide, unhide the lab image, otherwise hide it.

            if(event.currentSlide.getAttribute("data-state") === "lab") {
            document.getElementById("lab_pic").style.visibility="visible";
            }else{
            document.getElementById("lab_pic").style.visibility="hidden";
            }

            } );

		</script>

	</body>
</html>
